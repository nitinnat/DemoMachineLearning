{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cf0641-8e58-4353-9617-559fb5d4c33a",
   "metadata": {
    "editable": false,
    "tags": [
     "o9_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is NOT editable. Overwrite variables on your own discretion.\n",
    "# Any changes other than the script code will NOT BE SAVED!\n",
    "# All cells are assumed to be script code cells, unless explictly tagged as 'o9_ignore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a136d5d-3aad-4e56-84a1-d82983b40172",
   "metadata": {
    "tags": [
     "o9_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Slice Dimension Attributes defined in the plugin. Please check all queries and replace <KEY HERE> with a valid name.\n",
    "# For example: If slice is defined by Version.[Version Name] and Time.[Month]\n",
    "# input_df = %ibpl Select ([Version].[Version Name].[<KEY HERE>] * [Time].[Month].[<KEY HERE>] * [Item].[Item Number]) on row, ({Measure.[M1], Measure.[M2]}) on column limit 5000;\n",
    "#                             update <KEY HERE> to valid names\n",
    "# input_df = %ibpl Select ([Version].[Version Name].[CurrentWorkingView] * [Time].[Month].[January] * [Item].[Item Number]) on row, ({Measure.[M1], Measure.[M2]}) on column limit 5000;\n",
    "\n",
    "input_df = %ibpl select (Version.[Version Name]*Product.[Product].[<KEY HERE>]*Time.FiscalWeek*SalesAccount.[Account]*Location.[Location]*{Measure.[DPSellOutUnitsActuals],Measure.[Mean Pricing Save PCT],Measure.[Placement Count],Measure.[Promotion Count],Measure.[DPSellOutPrice]});\n",
    "input_df.info()  # Printing info for the primary table\n",
    "predict_df = %ibpl select (Version.[Version Name]*Product.[Product].[<KEY HERE>]*Time.FiscalWeek*SalesAccount.[Account]*Location.[Location]*{Measure.[DPSellOutUnitsActuals],Measure.[Mean Pricing Save PCT],Measure.[Placement Count],Measure.[Promotion Count],Measure.[DPSellOutPrice]});\n",
    "\n",
    "\n",
    "# Initialize the O9DataLake with the input parameters and dataframes\n",
    "# Data can be accessed with O9DataLake.get(<Input Name>)\n",
    "# Overwritten values will not be reflected in the O9DataLake after initialization\n",
    "\n",
    "from o9_common_utils.O9DataLake import O9DataLake\n",
    "O9DataLake.init_data_lake({'input_df': input_df, 'predict_df': predict_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc3c91-0c56-44a5-8cca-3437df0a4888",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "exec plugin instance [aws_codelibcheck] for measures {[DPSellOutUnitsActuals]} using scope ([Product].[Product].Filter(#.Name in {[196426]}) * [Time].[Day] * [Version].[Version Name].[CurrentWorkingView]) using arguments {(NumExecutors, 2),(PythonPath, \"/opt/conda/envs/aa_storage/bin/python\"),([Param.o9_sys_log_level], \"DEBUG\")};\n",
    "\n",
    "\"\"\"\n",
    "from o9storage import storage_utils\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import shutil\n",
    "from os import path\n",
    "\n",
    "logger = logging.getLogger('o9_logger')\n",
    "bucket = \"test_sumanth_bucket\"\n",
    "local_storage_path = os.path.join(df_keys['user_storage_path'], bucket)\n",
    "test_folder_path = os.path.join(local_storage_path, \"test\")\n",
    "os.makedirs(test_folder_path)\n",
    "csv_path = os.path.join(test_folder_path, 'cross_env.csv')\n",
    "\n",
    "input_df.to_csv(csv_path)\n",
    "try:\n",
    "    logger.debug('********Before storage_push*******')\n",
    "    logger.debug(os.listdir(local_storage_path))\n",
    "    value = storage_utils.storage_push(bucket, local_storage_path, overwrite=True)\n",
    "    if value:\n",
    "        logger.debug(\"storage_push successful\")\n",
    "    else:\n",
    "        logger.debug(\"storage_push failed\")\n",
    "\n",
    "    shutil.rmtree(test_folder_path)\n",
    "    logger.debug('********Before storage_pull*******')\n",
    "    logger.debug(os.listdir(local_storage_path))\n",
    "    value = storage_utils.storage_pull(bucket, local_storage_path, overwrite=True)\n",
    "    if value:\n",
    "        logger.debug(\"storage_pull successful\")\n",
    "    else:\n",
    "        logger.debug(\"storage_pull failed\")\n",
    "    logger.debug('********After storage_pull*******')\n",
    "    logger.debug(os.listdir(local_storage_path))\n",
    "    import glob\n",
    "\n",
    "    for filename in glob.iglob(local_storage_path + '**/**/*', recursive=True):\n",
    "        logger.debug(filename)\n",
    "\n",
    "except:\n",
    "    logger.exception(\"Couldn't commit folder\")\n",
    "\n",
    "out_df = input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483d158-3b24-4f5e-b633-8ce0bda9ec24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[pyplatformhivetest] Tenant Conda Environment",
   "language": "python",
   "name": "genieaz_pyplatformhivetest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
